{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.layers import BatchNormalization,Flatten,Dense, Concatenate\n",
    "from tensorflow.python.keras.layers import Input,Activation,Dropout,Reshape,Softmax, Activation\n",
    "from tensorflow.python.keras import Sequential, models, optimizers, layers, losses, metrics, regularizers\n",
    "import tensorflow.python.keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import scipy.optimize as sop\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameters\n",
    "global_user = 20\n",
    "global_x_min = 0\n",
    "global_x_max = 1\n",
    "global_eta = 0.02\n",
    "global_epsilon = 0.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_fun(x,a): # input is numpy [None,20]\n",
    "    \"\"\" object function to minimize \"\"\"\n",
    "    x,a = x.reshape([-1,global_user]),a.reshape([-1,global_user])\n",
    "    res = 1-x*a  #[None,20]\n",
    "    res = res.reshape([-1,4,5]) #[None,4,5]\n",
    "    res = 1-np.prod(res,axis=-1) #[None,4]\n",
    "    res = np.prod(res,axis=-1) #[None]\n",
    "    res = res-global_eta*np.sum(a,axis=-1) #[None,]\n",
    "    return res #[None,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "x_train = np.tile(sio.loadmat('./data/x_train.mat')['p_linear'],[4,1,1])\n",
    "x_val = np.tile(sio.loadmat('./data/x_val.mat')['p_linear'],[4,1,1])\n",
    "x_test = np.tile(sio.loadmat('./data/x_test.mat')['p_linear'],[4,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all actions\n",
    "def load_actions(name='val'):\n",
    "    action_val1 = sio.loadmat('./result/'+name+'_random_actions.mat')['action']\n",
    "    action_val2 = sio.loadmat('./result/'+name+'_greedy_actions.mat')['action']\n",
    "    action_val3 = sio.loadmat('./result/'+name+'_random_actions_v1.mat')['action']\n",
    "    action_val4 = sio.loadmat('./result/'+name+'_optimal_actions.mat')['action']\n",
    "    action_val = np.concatenate((action_val1,action_val2,action_val3,action_val4),axis=0)#action_val3\n",
    "    return action_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_train = load_actions(name='train')\n",
    "action_val = load_actions(name='val')\n",
    "action_test = load_actions(name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maxi_model(hiddens,model_name):\n",
    "    \"\"\"maxi models \"\"\"\n",
    "    xa = Input(shape=(global_user*2,),name='input')\n",
    "    a = xa[:,global_user:]    \n",
    "    h = Dense(hiddens[0],activation=None,name='hidden_0')(xa)\n",
    "    h = Activation(activation='relu',name='Act_0')(h)\n",
    "    for i,h_num in enumerate(hiddens[1:]):\n",
    "        h = Dense(h_num,activation='relu',name='hidden_{}'.format(i+1))(h)\n",
    "        h = Activation(activation='relu',name='Act_{}'.format(i+1))(h)\n",
    "    out = Dense(units=global_user,activation='tanh',name='out')(h)#noise\n",
    "    out = 0.71*out*a\n",
    "    model = models.Model(inputs=xa,outputs=out,name=model_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pair = np.hstack((x_train.reshape([-1,global_user]),action_train.reshape([-1,global_user])))\n",
    "print(x_train_pair.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :\t ./checkpoints_pretrain_new/max_model_layer2_200_lam1\n",
      "WARNING:tensorflow:From C:\\Users\\Zhihui\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Zhihui\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:175: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n",
      "WARNING:tensorflow:From C:\\Users\\Zhihui\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2373\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1454\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1350\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1259\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1177\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1118\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1050\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1000\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0956\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0922\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0890\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0859\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0837\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0804\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0792\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0769\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0746\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0738\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0718\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0708\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.0698\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.0676\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0672\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.0658\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0651\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.0636\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0635\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0617\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0612\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0614\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0600\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0599\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0590\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0579\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0573\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0572\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0566\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0560\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0558\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0546\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0548\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0546\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0541\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0536\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0529\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0525\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0525\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0526\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0516\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0513\n",
      "2 :\t ./checkpoints_pretrain_new/max_model_layer2_200_lam2\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2402\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1552\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1409\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1299\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1215\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1139\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1097\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1047\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1002\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0965\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0929\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0904\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0873\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0843\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0816\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0802\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0783\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0761\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0748\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0731\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0711\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0705\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0692\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0679\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0663\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0659\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0642\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0636\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0636\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0614\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0618\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0611\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0599\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0595\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0580\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0581\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0575\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0566\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0560\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0551\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0547\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0540\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0545\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0540\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0529\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0525\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0521\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0523\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0519\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0513\n",
      "5 :\t ./checkpoints_pretrain_new/max_model_layer2_200_lam5\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2442\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1669\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1537\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1419\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1322\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1248\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1185\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1129\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1096\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1059\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1022\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0987\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0955\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0931\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0904\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0878\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0858\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0836\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0818\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.0808\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0788\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0773\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.0758\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0743\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0734\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0721\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0712\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0698\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0693\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0680\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0671\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0666\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0656\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0649\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0646\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0638\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0627\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0619\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0615\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0605\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0606\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0600\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0598\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0587\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0580\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0578\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0572\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0575\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0565\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0564\n",
      "8 :\t ./checkpoints_pretrain_new/max_model_layer2_200_lam8\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2678\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1754\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1640\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1521\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1408\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1319\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1253\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1204\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1149\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1110\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1072\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1039\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1003\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0981\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0955\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0931\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0908\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0884\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0867\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0842\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0826\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0814\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.079 - 1s 11us/sample - loss: 0.0795\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0788\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0771\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0755\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0751\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0737\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0725\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0714\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0707\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0699\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0690\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0680\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0665\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0665\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0661\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0653\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0638\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0641\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0632\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0627\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0622\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0616\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0615\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0607\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0603\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0595\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0594\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0590\n",
      "10 :\t ./checkpoints_pretrain_new/max_model_layer2_200_lam10\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2485\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1770\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1647\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1522\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1420\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1336\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1252\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1196\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1149\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1102\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1072\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1047\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1016\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0991\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0958\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0944\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0918\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0893\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0884\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0861\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0837\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0831\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0815\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0796\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0779\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0764\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0755\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0748\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0734\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0723\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0716\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0702\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0692\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0690\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0684\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0670\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0665\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0659\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0654\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0644\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0638\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0634\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0630\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0619\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0613\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0616\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0605\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0604\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0600\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0595\n"
     ]
    }
   ],
   "source": [
    "# pre-trained for different lambda\n",
    "for lamb in [1,2,5,8,10]:\n",
    "    print(lamb,':\\t','./checkpoints_pretrain_new/max_model_layer2_200_lam{}'.format(lamb))\n",
    "    def my_max_loss(y_true, y_pred): #[None,300],None[150]\n",
    "        y_true_x = y_true[:,:global_user]+y_pred\n",
    "        y_true_a = y_true[:,global_user:]\n",
    "        y_true_x = tf.reshape(y_true_x,[-1,4,5])\n",
    "        y_true_a = tf.reshape(y_true_a,[-1,4,5])\n",
    "        \n",
    "        xa = 1-(y_true_x)*y_true_a #shape=(None,4,5)\n",
    "        loss = K.prod(1-K.prod(xa,axis=-1),axis=-1,keepdims=True) # shape=(None,1)\n",
    "        loss = loss-global_eta*K.sum(K.sum(y_true_a,axis=-1),axis=-1,keepdims=True) # shape(None,1)\n",
    "\n",
    "        bounds = K.sqrt(K.sum(K.square(y_pred),axis=-1,keepdims=True))-global_epsilon # shape: (None,1)\n",
    "        bounds1 = K.sum(K.sum(K.maximum(1.0,y_true_x)-1,axis=-1),axis=-1,keepdims=True)\n",
    "        bounds2 = K.sum(K.sum(K.maximum(0.0,-1*y_true_x),axis=-1),axis=-1,keepdims=True)\n",
    "        loss2 = K.maximum(bounds,0) # shape: (None,1)\n",
    "        return loss+lamb*loss2+10*(bounds1+bounds2)\n",
    "    \n",
    "    maxi_model = get_maxi_model(hiddens=[400,400],model_name='maxi')\n",
    "    maxi_model.compile(loss=my_max_loss,optimizer=optimizers.Adam(learning_rate=1e-3))\n",
    "    maxi_model.fit(x_train_pair,x_train_pair,batch_size=128,epochs=50,verbose=1)\n",
    "    maxi_model.save_weights('./checkpoints_pretrain/worst_case_model_layer2_400_lam{}'.format(lamb))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5656ff2f70495fd88149567ed70e45fa261f17d421b9d97d280b22568d58d7c5"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('p36')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
