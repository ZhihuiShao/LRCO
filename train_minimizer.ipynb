{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "import tensorflow as tf\n",
    "from tensorflow.distributions import Categorical\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.layers import BatchNormalization,Flatten,Dense,Input,Activation,Dropout,Reshape,Softmax, LSTM\n",
    "from tensorflow.python.keras.layers import Conv2D, Bidirectional, GRU\n",
    "from tensorflow.python.keras import Sequential, models, optimizers, layers, losses, metrics, regularizers\n",
    "from tensorflow.contrib.layers import xavier_initializer\n",
    "import tensorflow.python.keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import scipy.optimize as sop\n",
    "import math\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameters\n",
    "global_user = 20\n",
    "global_x_min = 0\n",
    "global_x_max = 1\n",
    "global_eta = 0.02\n",
    "global_epsilon = 0.71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maximizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the lam=5 maxi\n",
    "lamb = 1\n",
    "def my_max_loss(y_true, y_pred): #[None,300],None[150]\n",
    "    y_true_x = y_true[:,:global_user]+y_pred\n",
    "    y_true_a = y_true[:,global_user:]\n",
    "    y_true_x = tf.reshape(y_true_x,[-1,4,5])\n",
    "    y_true_a = tf.reshape(y_true_a,[-1,4,5])\n",
    "    xa = 1-(y_true_x)*y_true_a #shape=(None,4,5)\n",
    "    loss = K.prod(1-K.prod(xa,axis=-1),axis=-1,keepdims=True) # shape=(None,1)\n",
    "    loss = loss-global_eta*K.sum(K.sum(y_true_a,axis=-1),axis=-1,keepdims=True) # shape(None,1)\n",
    "    bounds = K.sqrt(K.sum(K.square(y_pred),axis=-1,keepdims=True))-global_epsilon # shape: (None,1)\n",
    "    bounds1 = K.sum(K.sum(K.maximum(1.0,y_true_x)-1,axis=-1),axis=-1,keepdims=True)\n",
    "    bounds2 = K.sum(K.sum(K.maximum(0.0,-1*y_true_x),axis=-1),axis=-1,keepdims=True)\n",
    "    loss2 = K.maximum(bounds,0) # shape: (None,1)\n",
    "    return loss+lamb*loss2+100*(bounds1+bounds2)\n",
    "# maximize model\n",
    "def get_maxi_model(hiddens,model_name):\n",
    "    \"\"\"maxi models \"\"\"\n",
    "    xa = Input(shape=(global_user*2,),name='input')\n",
    "    a = xa[:,global_user:]    \n",
    "    h = Dense(hiddens[0],activation=None,name='hidden_0')(xa)\n",
    "#     h = BatchNormalization(name='BN_0')(h)\n",
    "    h = Activation(activation='relu',name='Act_0')(h)\n",
    "    for i,h_num in enumerate(hiddens[1:]):\n",
    "        h = Dense(h_num,activation='relu',name='hidden_{}'.format(i+1))(h)\n",
    "#         h = BatchNormalization(name='BN_{}'.format(i+1))(h)\n",
    "        h = Activation(activation='relu',name='Act_{}'.format(i+1))(h)\n",
    "    out = Dense(units=global_user,activation='tanh',name='out')(h)#noise\n",
    "    out = 0.71*out*a\n",
    "    model = models.Model(inputs=xa,outputs=out,name=model_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_nodes = [200,200]#[200,200]\n",
    "layer_num = 2\n",
    "file_path = '../checkpoints_pretrain/worst_case_model_layer'\n",
    "model_1 = get_maxi_model(hiddens=hidden_nodes,model_name='maxi')\n",
    "model_1.compile(loss=my_max_loss,optimizer=optimizers.Adam(learning_rate=1e-5))\n",
    "model_1.load_weights(file_path+'{}_200_lam1'.format(layer_num))\n",
    "model_2 = get_maxi_model(hiddens=hidden_nodes,model_name='maxi')\n",
    "model_2.compile(loss=my_max_loss,optimizer=optimizers.Adam(learning_rate=1e-5))\n",
    "model_2.load_weights(file_path+'{}_200_lam2'.format(layer_num))\n",
    "\n",
    "model_5 = get_maxi_model(hiddens=hidden_nodes,model_name='maxi')\n",
    "model_5.compile(loss=my_max_loss,optimizer=optimizers.Adam(learning_rate=1e-5))\n",
    "model_5.load_weights(file_path+'{}_200_lam5'.format(layer_num))\n",
    "\n",
    "model_10 = get_maxi_model(hiddens=hidden_nodes,model_name='maxi')\n",
    "model_10.compile(loss=my_max_loss,optimizer=optimizers.Adam(learning_rate=1e-5))\n",
    "model_10.load_weights(file_path+'{}_200_lam8'.format(layer_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcuate_worst_case(x_val_pair):\n",
    "    x_val = x_val_pair[:,:global_user]\n",
    "    action_val = x_val_pair[:,global_user:]\n",
    "    \n",
    "    # get worse\n",
    "    x_val_worse_1 = model_1.predict(x_val_pair).reshape([-1,global_user])\n",
    "    x_val_worse_2 = model_2.predict(x_val_pair).reshape([-1,global_user])\n",
    "    x_val_worse_5 = model_5.predict(x_val_pair).reshape([-1,global_user])\n",
    "    x_val_worse_10 = model_10.predict(x_val_pair).reshape([-1,global_user])\n",
    "\n",
    "    dx_1 = np.sqrt(np.sum(np.square(x_val_worse_1),axis=-1,keepdims=True))\n",
    "    dx_2 = np.sqrt(np.sum(np.square(x_val_worse_2),axis=-1,keepdims=True))\n",
    "    dx_5 = np.sqrt(np.sum(np.square(x_val_worse_5),axis=-1,keepdims=True))\n",
    "    dx_10 = np.sqrt(np.sum(np.square(x_val_worse_10),axis=-1,keepdims=True))\n",
    "    \n",
    "    ratio_1 = np.maximum(dx_1/global_epsilon,1)\n",
    "    ratio_2 = np.maximum(dx_2/global_epsilon,1)\n",
    "    ratio_5 = np.maximum(dx_5/global_epsilon,1)\n",
    "    ratio_10 = np.maximum(dx_10/global_epsilon,1)\n",
    "\n",
    "    x_val_worse_add_1 = x_val_pair[:,:global_user]+x_val_worse_1/ratio_1\n",
    "    x_val_worse_add_2 = x_val_pair[:,:global_user]+x_val_worse_2/ratio_2\n",
    "    x_val_worse_add_5 = x_val_pair[:,:global_user]+x_val_worse_5/ratio_5\n",
    "    x_val_worse_add_10 = x_val_pair[:,:global_user]+x_val_worse_10/ratio_10\n",
    "    \n",
    "    x_val_worse_add_1 = np.minimum(np.maximum(x_val_worse_add_1,global_x_min),global_x_max)\n",
    "    x_val_worse_add_2 = np.minimum(np.maximum(x_val_worse_add_2,global_x_min),global_x_max)\n",
    "    x_val_worse_add_5 = np.minimum(np.maximum(x_val_worse_add_5,global_x_min),global_x_max)\n",
    "    x_val_worse_add_10 = np.minimum(np.maximum(x_val_worse_add_10,global_x_min),global_x_max)\n",
    "    \n",
    "    obj_1 = obj_fun(x_val_worse_add_1,action_val).reshape([-1,1])\n",
    "    obj_2 = obj_fun(x_val_worse_add_2,action_val).reshape([-1,1])\n",
    "    obj_5 = obj_fun(x_val_worse_add_5,action_val).reshape([-1,1])\n",
    "    obj_10 = obj_fun(x_val_worse_add_10,action_val).reshape([-1,1])\n",
    "    \n",
    "    obj_ensemble = np.hstack((obj_1,obj_2,obj_5,obj_10))\n",
    "    obj_worse = np.min(obj_ensemble,axis=-1,keepdims=True)\n",
    "    return obj_worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_robust_performance(x_val,actions): # return [None,1]\n",
    "    my_p = calcuate_worst_case(np.hstack((x_val.reshape([-1,global_user]),\n",
    "                                          actions.reshape([-1,global_user]))))\n",
    "    return my_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "x_train = sio.loadmat('../data/x_train.mat')['p_linear']\n",
    "x_val = sio.loadmat('../data/x_val.mat')['p_linear']\n",
    "x_test = sio.loadmat('../data/x_test.mat')['p_linear']\n",
    "x_test_true = sio.loadmat('../data/x_test.mat')['p_true']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_fun(x,a): # input is numpy [None,20]\n",
    "    \"\"\" object function to minimize \"\"\"\n",
    "    x,a = x.reshape([-1,global_user]),a.reshape([-1,global_user])\n",
    "    res = 1-x*a  #[None,20]\n",
    "    res = res.reshape([-1,4,5]) #[None,4,5]\n",
    "    res = 1-np.prod(res,axis=-1) #[None,4]\n",
    "    res = np.prod(res,axis=-1) #[None]\n",
    "    res = res-global_eta*np.sum(a,axis=-1) #[None,]\n",
    "    return res #[None,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = [50,50]\n",
    "global_T = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def the actor graph # begin by result all\n",
    "tf.random.set_random_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "# define the graph\n",
    "x_input = tf.placeholder(dtype=tf.float32,shape=[None,global_user,],name='x_input')\n",
    "a_value = tf.placeholder(dtype=tf.float32,shape=[None,1],name='value_input')\n",
    "with tf.variable_scope(\"actor\"):\n",
    "    h = Reshape(target_shape=(global_user,1,1),name='in_reshape')(x_input)\n",
    "    embed = Conv2D(filters=hidden_size[0],kernel_size=(1,1),strides=(1,1),activation='relu',name='embed')(h)\n",
    "    embed = Reshape(target_shape=(global_user,hidden_size[0]),name='in_reshape')(embed)\n",
    "    h1 = LSTM(hidden_size[1], return_sequences=True, return_state=False,name='LSTM1')(embed)\n",
    "    logit = LSTM(1, return_sequences=True, return_state=False,name='logit')(h1) #[None,10,1]\n",
    "    logit = Reshape(target_shape=(global_user,),name='out_reshape')(logit)#[None,10]\n",
    "    logit = logit/global_T\n",
    "    out_prob = Activation(activation='sigmoid',name='output')(logit)#[None,10]\n",
    "    out_prob = Reshape(target_shape=(global_user,1))(out_prob)\n",
    "    out_prob_r = 1-out_prob\n",
    "    out_prob_final = tf.concat((out_prob,out_prob_r),axis=-1)#[None,10,2]\n",
    "    # obtain probability by sampling and get the onehot_p as the final action\n",
    "    dist = Categorical(probs=out_prob_final)\n",
    "    action = dist.sample()\n",
    "    action = tf.cast(action,tf.int32) #shape=(None,10)\n",
    "    \n",
    "    select_action = tf.placeholder(dtype=tf.int32,shape=[None,global_user],name='select_action')\n",
    "    log_p = dist.log_prob(select_action) #shape=(None,15) corresponding to the log of position\n",
    "    log_p_sum = tf.reduce_sum(log_p,axis=-1,keep_dims=True)\n",
    "    reward = tf.placeholder(dtype=tf.float32,shape=[None,1],name='reward')\n",
    "    \n",
    "    # get the loss and optimizer\n",
    "    delta_reward = reward-a_value # shape(None,1)\n",
    "    actor_loss = tf.reduce_mean(-1*delta_reward*log_p_sum,axis=0) # shape(0,)\n",
    "    \n",
    "    # set for lr decay\n",
    "    global_step1 = tf.Variable(0, trainable=False, name=\"global_step1\")\n",
    "    lr1_start = 2e-3 # initial learning rate\n",
    "    lr1_decay_rate = 0.9 # learning rate decay rate\n",
    "    lr1_decay_step = 20*10 # learning rate decay step\n",
    "    lr1 = tf.train.exponential_decay(lr1_start,global_step1,lr1_decay_step,\n",
    "                                     lr1_decay_rate, staircase=False, name=\"learning_rate1\")\n",
    "    \n",
    "    actor_opt = tf.train.AdamOptimizer(learning_rate=lr1,beta1=0.9,beta2=0.99, epsilon=0.0000001)   \n",
    "    gvs = actor_opt.compute_gradients(actor_loss)\n",
    "    capped_gvs = [(tf.clip_by_norm(grad, 1.), var) for grad, var in gvs if grad is not None]\n",
    "    actor_train = actor_opt.apply_gradients(capped_gvs,global_step=global_step1) #actor_train = actor_opt.minimize(actor_loss)\n",
    "    \n",
    "saver = tf.train.Saver(max_to_keep=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "avg_rewar_list = []\n",
    "avg_log_p_sum_list = []\n",
    "train_size = 1000\n",
    "for i in range(100):\n",
    "    # train actor\n",
    "    for _ in range(10): #train 10 times\n",
    "        index = np.random.choice(15000,train_size)\n",
    "        actor_x_input = x_train[index]\n",
    "        # predict action\n",
    "        predict_action = sess.run(action,{x_input:actor_x_input}) #[None,10]\n",
    "        predict_reward = get_robust_performance(actor_x_input,predict_action) #[None,1]\n",
    "        # 1. simulate the avg reward\n",
    "        avg_reward = np.zeros((train_size,0)) #[None,0]\n",
    "        for _ in range(20):\n",
    "            onepass_action = sess.run(action,{x_input:actor_x_input}) #[None,5]\n",
    "            onepass_reward = get_robust_performance(actor_x_input,onepass_action) #[None,1]\n",
    "            \n",
    "            avg_reward = np.hstack((avg_reward,onepass_reward))\n",
    "        avg_reward = np.mean(avg_reward,axis=-1,keepdims=True) #(None,1)\n",
    "        # 2. train actor\n",
    "        sess.run(actor_train,{x_input:actor_x_input,select_action:predict_action,\n",
    "                              reward:predict_reward,a_value:avg_reward})        \n",
    "    saver.save(sess, './LSTM/' + 'model_2layer_50.ckpt', global_step=i+1)\n",
    "    if i%1==0:\n",
    "        cur_action = sess.run(action,{x_input:x_val})\n",
    "        cur_reward = get_robust_performance(x_val,cur_action)\n",
    "        \n",
    "        cur_log_p_sum,cur_lr1 = sess.run([log_p_sum,lr1],\n",
    "                                         {x_input:x_val,\n",
    "                                          select_action:cur_action})\n",
    "        print(np.mean(cur_reward),np.mean(np.exp(cur_log_p_sum)),cur_lr1)\n",
    "        avg_rewar_list.append(np.mean(cur_reward))\n",
    "        avg_log_p_sum_list.append(np.mean(np.exp(cur_log_p_sum)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
